.. _Evaluators page:

Evaluators
************

Evaluators are components that can be used to evaluate the data, the model, or
the predictions. The evaluations are typically represented through
text reports, point clouds, and plots. An :class:`.Evaluator` component is
typically used inside pipelines to assess the performance of a machine learning
model or to understand the insights of a neural network. Readers should be
familiar with :ref:`pipelines <Pipelines page>` to understand how to include
evaluators in their workflows.




Classification evaluator
=========================


The :class:`.ClassificationEvaluator` assumes there is a labeled point cloud
and that some predictions have been computed for that point cloud. It will
consider the predictions and reference labels at the current pipeline's state
and will evaluate them in different ways. A :class:`.ClassificationEvaluator`
can be defined inside a pipeline using the JSON below:


.. code-block:: json

    {
        "eval": "ClassificationEvaluator",
        "class_names": ["Ground", "Vegetation", "Building", "Urban furniture", "Vehicle"],
        "metrics": ["OA", "P", "R", "F1", "IoU", "wP", "wR", "wF1", "wIoU", "MCC", "Kappa"],
        "class_metrics": ["P", "R", "F1", "IoU"],
        "report_path": "*report/global_eval.log",
        "class_report_path": "*report/class_eval.log",
        "confusion_matrix_report_path" : "confusion_matrix.log",
        "confusion_matrix_plot_path" : "confusion_matrix.svg",
        "class_distribution_report_path": "class_distribution.log",
        "class_distribution_plot_path": "class_distribution.svg"
    }


The JSON above defines a :class:`.ClassificationEvaluator` that will consider
many metrics, from the overall accuracy to the Cohen's kappa score, to evaluate
the predicted point clouds. Some metrics will also be considered to compute
class-wise scores. On top of that, the confusion matrix and the distribution of
the points among the classes will be analyzed. All the evaluations can be
exported as a report, typically a text file containing the data or a plot for
quick visualization.


**Arguments**

-- ``class_names``
    A list with the names for the classes. These names will be used to
    represent the classes in the plots and the reports.


-- ``metrics``
    The metrics to evaluate the classification.
    Supported class metrics are:

    * ``"OA"`` Overall accuracy.
    * ``"P"`` Precision.
    * ``"R"`` Recall.
    * ``"F1"`` F1 score (harmonic mean of precision and recall).
    * ``"IoU"`` Intersection over union (also known as Jaccard index).
    * ``"wP"`` Weighted precision (weights by the number of true instances for each class).
    * ``"wR"`` Weighted recall (weights by the number of true instances for each class).
    * ``"wF1"`` Weighted F1 score (weights by the number of true instances for each class).
    * ``"wIoU"`` Weighted intersection over union (weights by the number of true instances for each class).
    * ``"MCC"`` Matthews correlation coefficient.
    * ``"Kappa"`` Cohen's kappa score.


-- ``class_metrics``
    The metrics to evaluate the classification in a class-wise way.
    Supported class metrics are:

    * ``"P"`` Precision.
    * ``"R"`` Recall.
    * ``"F1"`` F1 score (harmonic mean of precision and recall).
    * ``"IoU"`` Intersection over union (also known as Jaccard index).


-- ``report_path``
    Path to write the evaluation of the classification to a text file.


-- ``class_report_path``
    Path to write the class-wise evaluation of the classification to a text
    file.


-- ``confusion_matrix_report_path``
    Path to write the confusion matrix to a text file.

-- ``confusion_matrix_plot_path``
    Path to write the plot representing a confusion matrix to a file.


-- ``class_distribution_report_path``
    Path to write the class distribution report to a text file.


-- ``class_distribution_plot_path``
    Path to write the plot representing the class distribution to a text file.



**Output**




Deep learning model evaluator
==============================

The :class:`.DLModelEvaluator` assumes there is a deep learning at the current
pipeline's state that can be used to process the point cloud at the current
pipeline's state. Instead of returning the output point-wise predictions,
the values of the output layer and some internal feature representation will be
returned to be visualized directly in the point cloud. Note that the internal
feature representation might need an enormous amount of memory as it scales
depending on how many features are generated by the architecture at the studied
layer. A :class:`.DLModelEvaluator` can be defined inside a pipeline using the
JSON below:


.. code-block:: json

    {
        "eval": "DLModelEvaluator",
        "pointwise_model_output_path": "pwise_out.laz",
        "pointwise_model_activations_path": "pwise_activations.laz"
    }

The JSON above defines a :class:`.DLModelEvaluator` that will export the
values of the output layer to the file `pwise_out.laz` and a representation
of the features in the hidden layers to the file `pwise_activations.laz`.


**Arguments**

-- ``pointwise_model_output_path``
    Where to export the point cloud with the point-wise outputs of the neural
    network.

-- ``pointwise_model_activations_path``
    Where to export the point cloud with the internal features of the neural
    network.


**Output**
